{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **YOLOv8 TRAIN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Initial configuration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"ultralytics<=8.3.40\"\n",
    "# !pip install ultralytics==8.2.103\n",
    "# !pip install comet_ml==3.47.4\n",
    "# !pip install py-cpuinfo\n",
    "# !pip install psutil\n",
    "# !pip install gputil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import comet_ml\n",
    "import cpuinfo\n",
    "import glob\n",
    "import GPUtil\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import platform\n",
    "import psutil\n",
    "import shutil\n",
    "import subprocess\n",
    "import torch\n",
    "import urllib.request\n",
    "import yaml\n",
    "\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine specifications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_machine_specs():\n",
    "  # Operating System\n",
    "  print(\"Operating System:\")\n",
    "  print(f\"  Name: {platform.system()} {platform.release()}\")\n",
    "  print(f\"  Version: {platform.version()}\")\n",
    "  print(f\"  Processor: {platform.processor()}\")\n",
    "  print(f\"  Architecture: {platform.architecture()[0]}\\n\")\n",
    "\n",
    "  # OS - Distribution\n",
    "  print(\"OS - Distribution:\")\n",
    "  print(f\"  pretty name: {platform.freedesktop_os_release()['PRETTY_NAME']}\")\n",
    "  print(f\"  name: {platform.freedesktop_os_release()['NAME']}\")\n",
    "  print(f\"  version: {platform.freedesktop_os_release()['VERSION']}\")\n",
    "  print(f\"  version codename: {platform.freedesktop_os_release()['VERSION_CODENAME']}\")\n",
    "  print(f\"  id: {platform.freedesktop_os_release()['ID']}\")\n",
    "  print(f\"  id like: {platform.freedesktop_os_release()['ID_LIKE']} \\n\")\n",
    "\n",
    "  # CPU Information\n",
    "  cpu = cpuinfo.get_cpu_info()\n",
    "  print(\"CPU Information:\")\n",
    "  print(f\"  Processor: {cpu['brand_raw']}\")\n",
    "  print(f\"  Cores: {psutil.cpu_count(logical=False)}\")\n",
    "  print(f\"  Threads: {psutil.cpu_count(logical=True)}\")\n",
    "  print(f\"  Max Frequency: {psutil.cpu_freq().max:.2f} MHz\\n\")\n",
    "\n",
    "  # Memory Information\n",
    "  virtual_memory = psutil.virtual_memory()\n",
    "  print(\"Memory Information:\")\n",
    "  print(f\"  Total: {virtual_memory.total / (1024 ** 3):.2f} GB\")\n",
    "  print(f\"  Available: {virtual_memory.available / (1024 ** 3):.2f} GB\\n\")\n",
    "\n",
    "  # Disk Information\n",
    "  disk_usage = psutil.disk_usage('/')\n",
    "  print(\"Disk Information:\")\n",
    "  print(f\"  Total: {disk_usage.total / (1024 ** 3):.2f} GB\")\n",
    "  print(f\"  Used: {disk_usage.used / (1024 ** 3):.2f} GB\")\n",
    "  print(f\"  Free: {disk_usage.free / (1024 ** 3):.2f} GB\\n\")\n",
    "\n",
    "  # GPU Information (if available)\n",
    "  try:\n",
    "    gpus = GPUtil.getGPUs()\n",
    "    print(\"GPU Information:\")\n",
    "    for gpu in gpus:\n",
    "      print(f\"  GPU: {gpu.name}\")\n",
    "      print(f\"  Memory Total: {gpu.memoryTotal} MB\")\n",
    "      print(f\"  Memory Free: {gpu.memoryFree} MB\")\n",
    "      print(f\"  Memory Used: {gpu.memoryUsed} MB\\n\")\n",
    "  except ImportError:\n",
    "    print(\"GPU Information: GPUtil not installed. Install it using `pip install gputil`.\\n\")\n",
    "\n",
    "  # Python Information\n",
    "  print(\"Python Environment:\")\n",
    "  print(f\"  Version: {platform.python_version()}\")\n",
    "  print(f\"  Compiler: {platform.python_compiler()}\\n\")\n",
    "\n",
    "print_machine_specs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graphic card features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify cuda available device\n",
    "cuda_device_num = torch.cuda.device_count()\n",
    "if not cuda_device_num:\n",
    "  print(\"\\033[93m WARNING: No cuda devices found. \\033[0m\")\n",
    "else:\n",
    "  print(f\"\\033[34m INFO: There {'is' if cuda_device_num == 1 else 'are'} {cuda_device_num} pytorch cuda devices. \\033[0m\")\n",
    "  print(f\"\\033[34m       Pyorch cuda version: {torch.version.cuda} \\033[0m\")\n",
    "  print(f\"\\033[34m-\\033[0m\" * 35)\n",
    "  for index in  range(cuda_device_num):\n",
    "    print(f\"\\033[34m GPU {index}: {torch.cuda.get_device_name(index)} \\033[0m\")\n",
    "    print(f\"\\033[34m \\tTotal cuda device memory {torch.cuda.mem_get_info(0)[1] // 2 ** 20} MiB\\033[0m\")\n",
    "    print(f\"\\033[34m \\tFree cuda device memory {torch.cuda.mem_get_info(index)[0] // 2 ** 20} MiB\\033[0m\\n\")\n",
    "\n",
    "  print(\"Graphics card information\")\n",
    "  print(subprocess.check_output(\"nvidia-smi\").decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Directory structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run local or not\n",
    "PROJ_ROOT = os.getcwd()\n",
    "local = True if os.path.basename(PROJ_ROOT) == \"notebooks\" else False\n",
    "\n",
    "# Directories path\n",
    "if not local:\n",
    "  os.makedirs(\"models\", exist_ok=True)\n",
    "  data_relative_path =\"data\"\n",
    "  models_relative_path = \"models\"\n",
    "else:\n",
    "  data_relative_path =\"../data/processed\"\n",
    "  models_relative_path = \"../models\"\n",
    "\n",
    "MODELS_DIR = os.path.join(PROJ_ROOT, models_relative_path)\n",
    "PROCESSED_DATA_DIR = os.path.join(PROJ_ROOT, data_relative_path)\n",
    "\n",
    "# Print directories paths\n",
    "print(f\"\\033[34m INFO: Models in {MODELS_DIR} \\033[0m\")\n",
    "print(f\"\\033[34m INFO: Processed data in {PROCESSED_DATA_DIR} \\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuration variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration class\n",
    "class CFG:\n",
    "  # Classes\n",
    "  CLASSES = [\"hard_hat\",\n",
    "            \"no_hard_hat\",\n",
    "            \"no_safety_harness\",\n",
    "            \"no_safety_vest\",\n",
    "            \"person\",\n",
    "            \"safety_harness\",\n",
    "            \"safety_vest\"]\n",
    "\n",
    "  # Model\n",
    "  MODEL_VERSION = \"v8\"\n",
    "  MODEL_SIZE = \"n\" # n, s, m, l, x\n",
    "  PRETRAINED = True\n",
    "  MODEL_NAME = f\"yolo{MODEL_VERSION}{MODEL_SIZE}\"\n",
    "  BASE_MODEL = f\"{MODEL_NAME}.{'pt' if PRETRAINED else 'yaml'}\"\n",
    "\n",
    "  # Dataset\n",
    "  DATASET_VERSION = 5\n",
    "  DATASET_NAME = f\"ppe_dataset_v{DATASET_VERSION}\"\n",
    "  DATASET_PATH = os.path.join(PROCESSED_DATA_DIR, DATASET_NAME)\n",
    "  DATASET_YAML_PATH = os.path.join(DATASET_PATH, \"data.yaml\")\n",
    "\n",
    "  # Train variables\n",
    "  DEBUG = False\n",
    "  EPOCHS = 4 if DEBUG else 4\n",
    "  PATIENCE = 40\n",
    "  FRACTION = 0.01 if DEBUG else 0.01\n",
    "  TRAIN_DEVICE = 0 if cuda_device_num else \"cpu\"\n",
    "  TRAIN_MODEL_PATH = os.path.join(MODELS_DIR, \"base\", BASE_MODEL) if PRETRAINED else BASE_MODEL\n",
    "  TRAIN_PROJECT_NAME = f\"train_{MODEL_NAME}_ppe_detection{'_debug' if DEBUG else ''}\"\n",
    "  TRAIN_PROJECT_PATH = os.path.join(MODELS_DIR, TRAIN_PROJECT_NAME)\n",
    "  TRAIN_NAME = f\"{'pt' if PRETRAINED else 'yaml'}_{EPOCHS}_epochs\"\n",
    "\n",
    "# Print information\n",
    "if not CFG.DEBUG:\n",
    "  print(\"\\033[34m INFO: The configuration is ready for TRAINING. \\033[0m\")\n",
    "else:\n",
    "  print(\"\\033[93m WARNING: Configuration is set on DEBUG. \\033[0m\")\n",
    "\n",
    "print(f\"\\nModel information\")\n",
    "print(f\"Base modell: {CFG.BASE_MODEL}\")\n",
    "\n",
    "print(f\"\\nDataset information\")\n",
    "print(f\"Dataset path: {CFG.DATASET_PATH}\")\n",
    "\n",
    "print(\"\\nTraining information\")\n",
    "print(f\"Train model path: {CFG.TRAIN_MODEL_PATH}\")\n",
    "print(f\"Train project path: {CFG.TRAIN_PROJECT_PATH}\")\n",
    "print(f\"Train name: {CFG.TRAIN_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "dataset_path_exist = os.path.isdir(CFG.DATASET_PATH)\n",
    "dataset_yaml_file_exist = os.path.isfile(CFG.DATASET_YAML_PATH)\n",
    "\n",
    "# Check if path exists\n",
    "if not dataset_path_exist or not dataset_yaml_file_exist:\n",
    "  print(\"\\033[93m WARNING: Check dataset path or download again. \\033[0m\")\n",
    "else:\n",
    "  print(\"\\033[34m INFO: The dataset exists. \\033[0m\\n\")\n",
    "  # Plot dataset yaml file\n",
    "  with open(CFG.DATASET_YAML_PATH, \"r\") as file:\n",
    "    try:\n",
    "      data = yaml.safe_load(file)\n",
    "      yaml_data = yaml.dump(data, default_style=False)\n",
    "      print(yaml_data)\n",
    "\n",
    "    except yaml.YAMLError as e:\n",
    "      print(\"Error reading YAML: \", e)\n",
    "  file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download YOLOv8 base models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donwload base model function\n",
    "def donwload_base_model(base_model = \"yolov8n.pt\"):\n",
    "  base_models_dir_path = os.path.join(MODELS_DIR, \"base\")\n",
    "  os.makedirs(base_models_dir_path, exist_ok=True)\n",
    "\n",
    "  model_file = os.path.join(base_models_dir_path, base_model)\n",
    "  # Model from yaml file\n",
    "  if \"yaml\" in base_model:\n",
    "    model_file = base_model\n",
    "    print(f\"Empty {model_file} was charged.\")\n",
    "\n",
    "  # Model from pt file\n",
    "  else:\n",
    "    if base_model not in os.listdir(base_models_dir_path):\n",
    "      print(f\"Downloading {base_model} ...\")\n",
    "      try:\n",
    "        urllib.request.urlretrieve(f\"https://github.com/ultralytics/assets/releases/download/v8.2.0/{base_model}\", model_file)\n",
    "        print(f\"The model {base_model} was downloaded.\")\n",
    "      except:\n",
    "        print(f\"Something went wrong with downloading ...\")\n",
    "    else:\n",
    "      print(f\"The model {base_model} already exists.\")\n",
    "\n",
    "# Download the base model\n",
    "donwload_base_model(base_model=CFG.BASE_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \".yaml\" != os.path.splitext(CFG.TRAIN_MODEL_PATH)[1]:\n",
    "  if not os.path.isfile(CFG.TRAIN_MODEL_PATH):\n",
    "    print(f\"\\033[31m ERROR: Is posible the base model {CFG.TRAIN_MODEL_PATH} don't exist. \\033[0m\")\n",
    "  else:\n",
    "    print(f\"\\033[34m INFO: The base model {CFG.TRAIN_MODEL_PATH} exists. \\033[0m\")\n",
    "else:\n",
    "  print(f\"\\033[34m INFO: The base model {CFG.TRAIN_MODEL_PATH} is a YAML file. \\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project configuration\n",
    "train_path = os.path.join(CFG.TRAIN_PROJECT_PATH, CFG.TRAIN_NAME)\n",
    "if os.path.isdir(train_path):\n",
    "  shutil.rmtree(train_path)\n",
    "\n",
    "print(\"Train model path:\\t\", CFG.TRAIN_MODEL_PATH)\n",
    "print(\"Train project name:\\t\", CFG.TRAIN_PROJECT_NAME)\n",
    "print(\"Train project path:\\t\", CFG.TRAIN_PROJECT_PATH)\n",
    "print(\"Train name:\\t\", CFG.TRAIN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_train = {\n",
    "  \"data\": CFG.DATASET_YAML_PATH,\n",
    "  \"epochs\": CFG.EPOCHS,\n",
    "  \"time\": None,\n",
    "  \"patience\": CFG.PATIENCE,\n",
    "  \"batch\": 16,\n",
    "  \"imgsz\": 640,\n",
    "  \"save\": True,\n",
    "  \"save_period\": -1,\n",
    "  \"cache\": False,\n",
    "  \"device\": CFG.TRAIN_DEVICE,\n",
    "  \"project\": CFG.TRAIN_PROJECT_PATH,\n",
    "  \"name\": CFG.TRAIN_NAME,\n",
    "  \"exist_ok\": False,\n",
    "  \"pretrained\": True,\n",
    "  \"optimizer\": \"auto\",\n",
    "  \"classes\": None,\n",
    "  \"multi_scale\": False,\n",
    "  \"close_mosaic\": 10,\n",
    "  \"resume\": False,\n",
    "  \"amp\": True,\n",
    "  \"fraction\": CFG.FRACTION,\n",
    "  \"profile\": False,\n",
    "  \"freeze\": None,\n",
    "  \"lr0\": 0.01,\n",
    "  \"lrf\": 0.01,\n",
    "  \"momentum\": 0.937,\n",
    "  \"weight_decay\": 0.0005,\n",
    "  \"warmup_epochs\": 3.0,\n",
    "  \"warmup_momentum\": 0.8,\n",
    "  \"warmup_bias_lr\": 0.1,\n",
    "  \"box\": 7.5,\n",
    "  \"cls\": 0.5,\n",
    "  \"val\": True,\n",
    "  \"iou\": 0.8,\n",
    "  \"augment\": True,\n",
    "  \"plots\": True\n",
    "}\n",
    "\n",
    "for key, value in cfg_train.items():\n",
    "    print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comet ML configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comet config\n",
    "comet_ml.login()\n",
    "experiment_config = comet_ml.ExperimentConfig(name=CFG.TRAIN_NAME)\n",
    "exp = comet_ml.start(project_name=CFG.TRAIN_PROJECT_NAME, experiment_config=experiment_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  train_model = YOLO(CFG.TRAIN_MODEL_PATH)\n",
    "  print(f\"The {CFG.TRAIN_MODEL_PATH} was loaded.\")\n",
    "except:\n",
    "  print(f\"Error loading the {CFG.TRAIN_MODEL_PATH} model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = train_model.train(**cfg_train)\n",
    "exp.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"map50-95\", \":\", train_results.box.map)\n",
    "print(\"map50\", \":\", train_results.box.map50)\n",
    "print(\"map75\", \":\", train_results.box.map75)\n",
    "print(\"maps\", \":\", train_results.box.maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Images of the train results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_path = train_results.save_dir\n",
    "train_image_files = [\n",
    "  i for i in\n",
    "  glob.glob(f\"{train_results_path}/*.png\") + glob.glob(f\"{train_results_path}/*.jpg\")\n",
    "  if \"batch\" not in i\n",
    "]\n",
    "\n",
    "train_image_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot images of the train results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in sorted(train_image_files):\n",
    "  image_name = image.split(\"/\")[-1]\n",
    "  print(image_name)\n",
    "\n",
    "  img = Image.open(image)\n",
    "  plt.imshow(img)\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()\n",
    "\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read CSV result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{train_results_path}/results.csv\")\n",
    "df = df.rename(columns=lambda x: x.replace(\" \", \"\"))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*\"*50)\n",
    "print(\"\\nBest Training Box loss: \", df[\"train/box_loss\"].min(), \", on epoch: \", df[\"train/box_loss\"].argmin() + 1)\n",
    "print(\"\\nBest Validation Box loss: \", df[\"val/box_loss\"].min(), \", on epoch: \", df[\"val/box_loss\"].argmin() + 1, \"\\n\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"\\nBest Training Cls loss: \", df[\"train/cls_loss\"].min(), \", on epoch: \", df[\"train/cls_loss\"].argmin() + 1)\n",
    "print(\"\\nBest Validation Cls loss: \", df[\"val/cls_loss\"].min(), \", on epoch: \", df[\"val/cls_loss\"].argmin() + 1, \"\\n\")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"\\nBest Training DFL loss: \", df[\"train/dfl_loss\"].min(), \", on epoch: \", df[\"train/dfl_loss\"].argmin() + 1)\n",
    "print(\"\\nBest Validation DFL loss: \", df[\"val/dfl_loss\"].min(), \", on epoch: \", df[\"val/dfl_loss\"].argmin() + 1, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 20), sharex=True)\n",
    "\n",
    "#Training and Validation box_loss\n",
    "ax1.set_title(\"Box Loss\")\n",
    "ax1.plot(df[\"epoch\"], df[\"train/box_loss\"], label=\"Training box_loss\", marker=\"o\", linestyle=\"-\")\n",
    "ax1.plot(df[\"epoch\"], df[\"val/box_loss\"], label=\"Validation box_loss\", marker=\"o\", linestyle=\"-\")\n",
    "ax1.set_xlabel(\"Epochs\")\n",
    "ax1.set_ylabel(\"Box Loss\")\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Training and Validation cls_loss\n",
    "ax2.set_title(\"Cls Loss\")\n",
    "ax2.plot(df[\"epoch\"], df[\"train/cls_loss\"], label=\"Training cls_loss\", marker=\"o\", linestyle=\"-\")\n",
    "ax2.plot(df[\"epoch\"], df[\"val/cls_loss\"], label=\"Validation cls_loss\", marker=\"o\", linestyle=\"-\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Cls loss\")\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Training and Validation dfl_loss\n",
    "ax3.set_title(\"DFL Loss\")\n",
    "ax3.plot(df[\"epoch\"], df[\"train/dfl_loss\"], label=\"Training dfl_loss\", marker=\"o\", linestyle=\"-\")\n",
    "ax3.plot(df[\"epoch\"], df[\"val/dfl_loss\"], label=\"Validation dfl_loss\", marker=\"o\", linestyle=\"-\")\n",
    "ax3.set_xlabel(\"Epochs\")\n",
    "ax3.set_ylabel(\"DFL loss\")\n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "\n",
    "plt.suptitle(\"Training Metrics vs. Epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results_path = train_results.save_dir\n",
    "valid_image_files = [\n",
    "  i for i in\n",
    "  glob.glob(f\"{train_results_path}/*.png\") + glob.glob(f\"{train_results_path}/*.jpg\")\n",
    "  if \"val_batch\" in i\n",
    "]\n",
    "\n",
    "valid_image_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot images of the validation results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in sorted(valid_image_files):\n",
    "  image_name = image.split(\"/\")[-1]\n",
    "  print(image_name)\n",
    "\n",
    "  img = Image.open(image)\n",
    "  plt.imshow(img)\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()\n",
    "\n",
    "  print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
