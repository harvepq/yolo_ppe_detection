{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Export YOLOv8 model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Initial configuration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install onnx==1.17.0\n",
    "# !pip install onnxslim==0.1.34\n",
    "# !pip install onnxruntime==1.20.1\n",
    "# !pip install onnxruntime-gpu==1.20.1\n",
    "# !pip install tensorrt==10.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.103 ðŸš€ Python-3.12.7 torch-2.5.1+cu124 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4034MiB)\n",
      "Setup complete âœ… (8 CPUs, 7.6 GB RAM, 69.0/294.2 GB disk)\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graphic cards features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m INFO: There is 1 pytorch cuda devices. \u001b[0m\n",
      "\u001b[34m       Pyorch cuda version: 12.4 \u001b[0m\n",
      "\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\u001b[34m-\u001b[0m\n",
      "\u001b[34m GPU 0: NVIDIA GeForce GTX 1050 Ti \u001b[0m\n",
      "\u001b[34m \tTotal cuda device memory 4034 MiB\u001b[0m\n",
      "\u001b[34m \tFree cuda device memory 2222 MiB\u001b[0m\n",
      "\n",
      "Graphics card information\n",
      "Mon Jan 27 19:54:30 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.05              Driver Version: 560.35.05      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050 Ti     Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   42C    P0             N/A / ERR!  |    1812MiB /   4096MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2193      G   /usr/bin/gnome-shell                            1MiB |\n",
      "|    0   N/A  N/A     21344      C   ...nda3/envs/yolo_detection/bin/python       1764MiB |\n",
      "|    0   N/A  N/A     21676      C   ...nda3/envs/yolo_detection/bin/python         44MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify cuda available device\n",
    "cuda_device_num = torch.cuda.device_count()\n",
    "if not cuda_device_num:\n",
    "  print(\"\\033[93m WARNING: No cuda devices found. \\033[0m\")\n",
    "else:\n",
    "  print(f\"\\033[34m INFO: There {'is' if cuda_device_num == 1 else 'are'} {cuda_device_num} pytorch cuda devices. \\033[0m\")\n",
    "  print(f\"\\033[34m       Pyorch cuda version: {torch.version.cuda} \\033[0m\")\n",
    "  print(f\"\\033[34m-\\033[0m\" * 35)\n",
    "  for index in  range(cuda_device_num):\n",
    "    print(f\"\\033[34m GPU {index}: {torch.cuda.get_device_name(index)} \\033[0m\")\n",
    "    print(f\"\\033[34m \\tTotal cuda device memory {torch.cuda.mem_get_info(0)[1] // 2 ** 20} MiB\\033[0m\")\n",
    "    print(f\"\\033[34m \\tFree cuda device memory {torch.cuda.mem_get_info(index)[0] // 2 ** 20} MiB\\033[0m\\n\")\n",
    "\n",
    "  print(\"Graphics card information\")\n",
    "  print(subprocess.check_output(\"nvidia-smi\").decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Directory structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m INFO: Processed data in /home/harvey/Documents/yolo_ppe_detection/notebooks/../data/processed. \u001b[0m\n",
      "\u001b[34m INFO: Trained model in /home/harvey/Documents/yolo_ppe_detection/notebooks/../models/trained. \u001b[0m\n",
      "\u001b[93m WARNING: You need to load the trained model into /home/harvey/Documents/yolo_ppe_detection/notebooks/../models/trained. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run local or not\n",
    "PROJ_ROOT = os.getcwd()\n",
    "local = True if os.path.basename(PROJ_ROOT) == \"notebooks\" else False\n",
    "\n",
    "# Directories path\n",
    "if not local:\n",
    "  os.makedirs(\"models/trained\", exist_ok=True)\n",
    "  data_relative_path =\"data\"\n",
    "  models_relative_path = \"models\"\n",
    "else:\n",
    "  data_relative_path =\"../data/processed\"\n",
    "  models_relative_path = \"../models\"\n",
    "\n",
    "TRAINED_MODEL_DIR = os.path.join(PROJ_ROOT, models_relative_path, \"trained\")\n",
    "PROCESSED_DATA_DIR = os.path.join(PROJ_ROOT, data_relative_path)\n",
    "\n",
    "# Print directories paths\n",
    "print(f\"\\033[34m INFO: Processed data in {PROCESSED_DATA_DIR}. \\033[0m\")\n",
    "print(f\"\\033[34m INFO: Trained model in {TRAINED_MODEL_DIR}. \\033[0m\")\n",
    "\n",
    "# Print warning\n",
    "print(f\"\\033[93m WARNING: You need to load the trained model into {TRAINED_MODEL_DIR}. \\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Configuration variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset information\n",
      "Dataset path: /home/harvey/Documents/yolo_ppe_detection/notebooks/../data/processed/ppe_dataset_v5\n",
      "\n",
      "Export information\n",
      "Export format: engine\n",
      "Export trained model path: /home/harvey/Documents/yolo_ppe_detection/models/train_yolov8n_ppe_detection_debug/pt_3_epochs/weights/best.pt\n",
      "Export model path: /home/harvey/Documents/yolo_ppe_detection/notebooks/../models/trained/ppe_detection.pt\n"
     ]
    }
   ],
   "source": [
    "# Configuration class\n",
    "class CFG:\n",
    "  # Dataset settings (Roboflow)\n",
    "  DATASET_WORKSPACE = \"deeplearning-cwudo\"\n",
    "  DATASET_PROJECT = \"yolo_ppe_detection\"\n",
    "  DATASET_FORMAT = \"yolov8\"\n",
    "  DATASET_VERSION = 5\n",
    "  DATASET_NAME = f\"ppe_dataset_v{DATASET_VERSION}\"\n",
    "  DATASET_PATH = os.path.join(PROCESSED_DATA_DIR, DATASET_NAME)\n",
    "  DATASET_YAML_PATH = os.path.join(DATASET_PATH, \"data.yaml\")\n",
    "\n",
    "  # Export variables\n",
    "  EXPORT_FORMAT = \"engine\"\n",
    "  EXPORT_MODEL_NAME = \"ppe_detection.pt\"\n",
    "  EXPORT_DEVICE = \"0\" if cuda_device_num else \"cpu\"\n",
    "  EXPORT_TRAINED_MODEL_PATH = \"/home/harvey/Documents/yolo_ppe_detection/models/train_yolov8n_ppe_detection_debug/pt_3_epochs/weights/best.pt\"\n",
    "  EXPORT_MODEL_PATH = os.path.join(TRAINED_MODEL_DIR, EXPORT_MODEL_NAME)\n",
    "\n",
    "# Print information\n",
    "print(f\"\\nDataset information\")\n",
    "print(f\"Dataset path: {CFG.DATASET_PATH}\")\n",
    "\n",
    "print(\"\\nExport information\")\n",
    "print(f\"Export format: {CFG.EXPORT_FORMAT}\")\n",
    "print(f\"Export trained model path: {CFG.EXPORT_TRAINED_MODEL_PATH}\")\n",
    "print(f\"Export model path: {CFG.EXPORT_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verify dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m INFO: The dataset exists. \u001b[0m\n",
      "\n",
      "names:\n",
      "- hard_hat\n",
      "- no_hard_hat\n",
      "- no_safety_harness\n",
      "- no_safety_vest\n",
      "- person\n",
      "- safety_harness\n",
      "- safety_vest\n",
      "nc: 7\n",
      "roboflow:\n",
      "  license: CC BY 4.0\n",
      "  project: yolo_ppe_detection\n",
      "  url: https://universe.roboflow.com/deeplearning-cwudo/yolo_ppe_detection/dataset/5\n",
      "  version: 5\n",
      "  workspace: deeplearning-cwudo\n",
      "test: /home/harvey/Documents/yolo_ppe_detection/notebooks/../data/processed/ppe_dataset_v5/test/images\n",
      "train: /home/harvey/Documents/yolo_ppe_detection/notebooks/../data/processed/ppe_dataset_v5/train/images\n",
      "val: /home/harvey/Documents/yolo_ppe_detection/notebooks/../data/processed/ppe_dataset_v5/valid/images\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset paths\n",
    "dataset_path_exist = os.path.isdir(CFG.DATASET_PATH)\n",
    "dataset_yaml_file_exist = os.path.isfile(CFG.DATASET_YAML_PATH)\n",
    "\n",
    "# Check if path exists\n",
    "if not dataset_path_exist or not dataset_yaml_file_exist:\n",
    "  print(\"\\033[93m WARNING: Check dataset path or download again. \\033[0m\")\n",
    "else:\n",
    "  print(\"\\033[34m INFO: The dataset exists. \\033[0m\\n\")\n",
    "  # Plot dataset yaml file\n",
    "  with open(CFG.DATASET_YAML_PATH, \"r\") as file:\n",
    "    try:\n",
    "      data = yaml.safe_load(file)\n",
    "      yaml_data = yaml.dump(data, default_style=False)\n",
    "      print(yaml_data)\n",
    "\n",
    "    except yaml.YAMLError as e:\n",
    "      print(\"Error reading YAML: \", e)\n",
    "  file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Export**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy trained model and verify**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m INFO: The trained model from /home/harvey/Documents/yolo_ppe_detection/models/train_yolov8n_ppe_detection_debug/pt_3_epochs/weights/best.pt was copied to /home/harvey/Documents/yolo_ppe_detection/notebooks/../models/trained/ppe_detection.pt. \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(CFG.EXPORT_TRAINED_MODEL_PATH):\n",
    "  print(f\"\\033[31m ERROR: Is posible the trained model {CFG.EXPORT_TRAINED_MODEL_PATH} don't exist. \\033[0m\")\n",
    "else:\n",
    "  shutil.copy(CFG.EXPORT_TRAINED_MODEL_PATH, CFG.EXPORT_MODEL_PATH)\n",
    "  print(f\"\\033[34m INFO: The trained model from {CFG.EXPORT_TRAINED_MODEL_PATH} was copied to {CFG.EXPORT_MODEL_PATH}. \\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m INFO: Export in engine format, change the next arguments. \u001b[0m\n",
      "\u001b[34m\t imgsz \u001b[0m\n",
      "\u001b[34m\t half \u001b[0m\n",
      "\u001b[34m\t int8 \u001b[0m\n",
      "\u001b[34m\t dynamic \u001b[0m\n",
      "\u001b[34m\t simplify \u001b[0m\n",
      "\u001b[34m\t workspace \u001b[0m\n",
      "\u001b[34m\t batch \u001b[0m\n",
      "\u001b[34m\t data \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "export_args = [\n",
    "  \"format\",\n",
    "  \"imgsz\",\n",
    "  \"keras\",\n",
    "  \"optimize\",\n",
    "  \"half\",\n",
    "  \"int8\",\n",
    "  \"dynamic\",\n",
    "  \"simplify\",\n",
    "  \"opset\",\n",
    "  \"workspace\",\n",
    "  \"nms\",\n",
    "  \"batch\",\n",
    "  \"device\",\n",
    "  \"name\",\n",
    "  \"data\"\n",
    "]\n",
    "\n",
    "format_args = {\n",
    "  \"torchscript\": [1, 3, 11],\n",
    "  \"onnx\": [1, 4, 6, 7, 8, 11],\n",
    "  \"openvino\": [1, 4, 5, 6, 11],\n",
    "  \"engine\": [1, 4, 5, 6, 7, 9, 11, 14],\n",
    "  \"coreml\": [1, 4, 5, 10, 11],\n",
    "  \"saved_model\": [1, 2, 5, 11],\n",
    "  \"pb\": [1, 11],\n",
    "  \"tflite\": [1, 4, 5, 11],\n",
    "  \"edgetpu\": [1],\n",
    "  \"tfjs\": [1, 4, 5, 11],\n",
    "  \"paddle\": [1, 11],\n",
    "  \"mnn\": [1, 4, 5, 11],\n",
    "  \"ncnn\": [1, 4, 11],\n",
    "  \"imx\": [1, 5],\n",
    "  \"rknn\": [1, 11, 13]\n",
    "}\n",
    "\n",
    "print(f\"\\033[34m INFO: Export in {CFG.EXPORT_FORMAT} format, change the next arguments. \\033[0m\")\n",
    "id_args = format_args[CFG.EXPORT_FORMAT]\n",
    "for id_arg in id_args:\n",
    "  print(f\"\\033[34m\\t {export_args[id_arg]} \\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "format : engine\n",
      "imgsz : 640\n",
      "half : False\n",
      "int8 : True\n",
      "dynamic : True\n",
      "simplify : True\n",
      "workspace : 2\n",
      "batch : 1\n",
      "device : 0\n",
      "name : None\n",
      "data : /home/harvey/Documents/yolo_ppe_detection/notebooks/../data/processed/ppe_dataset_v5/data.yaml\n"
     ]
    }
   ],
   "source": [
    "cfg_export = {\n",
    "  \"format\": CFG.EXPORT_FORMAT,\n",
    "  \"imgsz\": 640,\n",
    "  #\"keras\": False,\n",
    "  #\"optimize\": False,\n",
    "  \"half\": False,\n",
    "  \"int8\": True,\n",
    "  \"dynamic\": True,\n",
    "  \"simplify\": True,\n",
    "  #\"opset\": None,\n",
    "  \"workspace\": 2,\n",
    "  #\"nms\": False,\n",
    "  \"batch\": 1,\n",
    "  \"device\": CFG.EXPORT_DEVICE,\n",
    "  \"name\": None,\n",
    "  \"data\": CFG.DATASET_YAML_PATH\n",
    "}\n",
    "\n",
    "for key, value in cfg_export.items():\n",
    "  print(key, \":\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The /home/harvey/Documents/yolo_ppe_detection/notebooks/../models/trained/ppe_detection.pt was loaded.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  export_model = YOLO(CFG.EXPORT_MODEL_PATH)\n",
    "  print(f\"The {CFG.EXPORT_MODEL_PATH} was loaded.\")\n",
    "except:\n",
    "  print(f\"Error loading the {CFG.EXPORT_MODEL_PATH} model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_model.export(**cfg_export)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
