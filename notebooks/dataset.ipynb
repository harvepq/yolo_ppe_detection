{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA SET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install roboflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow==1.1.49\n",
      "  Using cached roboflow-1.1.49-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: certifi in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (2024.8.30)\n",
      "Requirement already satisfied: idna==3.7 in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (3.7)\n",
      "Requirement already satisfied: cycler in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (1.4.7)\n",
      "Requirement already satisfied: matplotlib in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (3.9.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (1.26.4)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (11.0.0)\n",
      "Requirement already satisfied: python-dateutil in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (1.0.1)\n",
      "Requirement already satisfied: requests in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (2.32.3)\n",
      "Requirement already satisfied: six in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (4.67.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (1.0.0)\n",
      "Requirement already satisfied: filetype in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from roboflow==1.1.49) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from matplotlib->roboflow==1.1.49) (1.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from matplotlib->roboflow==1.1.49) (4.54.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from matplotlib->roboflow==1.1.49) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from matplotlib->roboflow==1.1.49) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/harvey/anaconda3/envs/yolo_detection/lib/python3.12/site-packages (from requests->roboflow==1.1.49) (3.4.0)\n",
      "Using cached roboflow-1.1.49-py3-none-any.whl (80 kB)\n",
      "Installing collected packages: roboflow\n",
      "  Attempting uninstall: roboflow\n",
      "    Found existing installation: roboflow 1.1.48\n",
      "    Uninstalling roboflow-1.1.48:\n",
      "      Successfully uninstalled roboflow-1.1.48\n",
      "Successfully installed roboflow-1.1.49\n"
     ]
    }
   ],
   "source": [
    "# !pip install roboflow==1.1.49"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import roboflow\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Environment configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run local o not\n",
    "PROJ_ROOT = os.getcwd()\n",
    "local = True if os.path.basename(PROJ_ROOT) == 'notebooks' else False\n",
    "\n",
    "# Directories\n",
    "if not local:\n",
    "  os.makedirs('data/processed', exist_ok=True)\n",
    "  data_relative_path ='data'\n",
    "else:\n",
    "  data_relative_path ='../data'\n",
    "\n",
    "DATA_DIR = os.path.join(PROJ_ROOT, data_relative_path)\n",
    "PROCESSED_DATA_DIR = os.path.join(DATA_DIR, 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DATA_CFG:\n",
    "  DATASET_VERSION = 5\n",
    "  DATASET_NAME = f\"ppe_dataset_v{DATASET_VERSION}\"\n",
    "  DATASET_PATH = os.path.join(PROCESSED_DATA_DIR, DATASET_NAME)\n",
    "\n",
    "  # Clases\n",
    "  CLASSES = ['hard_hat',\n",
    "            'no_hard_hat',\n",
    "            'no_safety_harness',\n",
    "            'no_safety_vest',\n",
    "            'person',\n",
    "            'safety_harness',\n",
    "            'safety_vest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login into roboflow\n",
    "roboflow.login()\n",
    "\n",
    "rf = roboflow.Roboflow()\n",
    "\n",
    "project = rf.workspace(\"deeplearning-cwudo\").project(\"yolo_ppe_detection\")\n",
    "version = project.version(DATA_CFG.DATASET_VERSION)\n",
    "dataset = version.download(model_format=\"yolov8\", location=DATA_CFG.DATASET_PATH, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify data yaml file\n",
    "def modify_yaml_file(file_path):\n",
    "  with open(file_path, 'r+') as file:\n",
    "    try:\n",
    "      data = yaml.safe_load(file)\n",
    "      file.seek(0)\n",
    "      file.truncate(0)\n",
    "\n",
    "      data[\"train\"] = os.path.join(DATA_CFG.DATASET_PATH, \"train/images\")\n",
    "      data[\"val\"] = os.path.join(DATA_CFG.DATASET_PATH, \"valid/images\")\n",
    "      data[\"test\"] = os.path.join(DATA_CFG.DATASET_PATH, \"test/images\")\n",
    "\n",
    "      yaml.dump(data, file)\n",
    "      yaml_data = yaml.dump(data, default_style=False)\n",
    "      print(yaml_data)\n",
    "\n",
    "    except yaml.YAMLError as e:\n",
    "      print('Error reading YAML: ', e)\n",
    "\n",
    "  file.close()\n",
    "\n",
    "data_file_path = os.path.join(DATA_CFG.DATASET_PATH, 'data.yaml')\n",
    "modify_yaml_file(data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize one image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, print_info = True, hide_axis = False):\n",
    "  if isinstance(image, str): # Check if it's a file path\n",
    "    img = Image.open(image)\n",
    "    plt.imshow(img)\n",
    "  elif isinstance(image, np.ndarray): # Check if it's a NumPy array\n",
    "    image = image[..., ::-1] # BGR to RGB\n",
    "    img = Image.fromarray(image)\n",
    "    plt.imshow(img)\n",
    "  else:\n",
    "    raise ValueError('Unsupported image format')\n",
    "\n",
    "  if print_info:\n",
    "    print('Type: ', type(img), '\\n')\n",
    "    print('Shape: ', np.array(img).shape, '\\n')\n",
    "\n",
    "  if hide_axis:\n",
    "    plt.axis('off')\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one: train, test or valid set\n",
    "subset = \"train\"\n",
    "images_path = os.path.join(DATA_CFG.DATASET_PATH, subset, \"images\")\n",
    "images_list = os.listdir(images_path)\n",
    "image_index = random.randint(0, len(images_list))\n",
    "\n",
    "# Random image path\n",
    "example_image_path = os.path.join(images_path, images_list[image_index])\n",
    "\n",
    "# Plot example image\n",
    "display_image(example_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize many images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_images_from_folder(folder_path, num_images = 20, seed = 0):\n",
    "\n",
    "  random.seed(seed)\n",
    "\n",
    "  # Get a list of image files in the folder\n",
    "  image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png', '.jpeg', '.gif'))]\n",
    "\n",
    "  # Make sure that we have a least num_images files to choose from\n",
    "  if len(image_files) < num_images:\n",
    "    raise ValueError('Not enough images in the folder')\n",
    "\n",
    "  # Randomly select num_images image files\n",
    "  selected_files = random.sample(image_files, num_images)\n",
    "\n",
    "  # Create a subplot grid\n",
    "  num_cols = 5\n",
    "  num_rows = (num_images + num_cols - 1) // num_cols\n",
    "  fig, axes = plt.subplots(num_rows, num_cols, figsize=(12,8))\n",
    "\n",
    "  for i, file_name in enumerate(selected_files):\n",
    "    # Open and display the image using PIL\n",
    "    img = Image.open(os.path.join(folder_path, file_name))\n",
    "\n",
    "    if num_rows == 1:\n",
    "      ax = axes[i % num_cols]\n",
    "    else:\n",
    "      ax = axes[i // num_cols, i % num_cols]\n",
    "\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "    # ax.set_title(file_name)\n",
    "\n",
    "  # Remove empty subplots\n",
    "  for i in range(num_images, num_rows * num_cols):\n",
    "    if num_rows == 1:\n",
    "      fig.delaxes(axes[i % num_cols])\n",
    "    else:\n",
    "      fig.delaxes(axes[i // num_cols, i % num_cols])\n",
    "\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one: train, test or valid set\n",
    "subset = \"train\"\n",
    "images_path = os.path.join(DATA_CFG.DATASET_PATH, subset, \"images\")\n",
    "plot_random_images_from_folder(images_path, num_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idx = {str(i): DATA_CFG.CLASSES[i] for i in range(len(DATA_CFG.CLASSES))}\n",
    "class_stat = {}\n",
    "data_len = {}\n",
    "class_info = []\n",
    "\n",
    "for subset in [\"train\", \"valid\", \"test\"]:\n",
    "  class_count = {DATA_CFG.CLASSES[i]: 0 for i in range(len(DATA_CFG.CLASSES))}\n",
    "\n",
    "  path = os.path.join(DATA_CFG.DATASET_PATH, subset, \"labels\")\n",
    "  for file in os.listdir(path):\n",
    "    with open(os.path.join(path, file)) as f:\n",
    "      lines = f.readlines()\n",
    "\n",
    "      # for cls in set([line[0] for line in lines]):\n",
    "      for cls in [line[0] for line in lines]:\n",
    "        class_count[class_idx[cls]] += 1\n",
    "\n",
    "    f.close()\n",
    "\n",
    "  data_len[subset] = len(os.listdir(path))\n",
    "  class_stat[subset] = class_count\n",
    "\n",
    "  class_info.append({'Subset': subset, **class_count, 'Data_Volume': data_len[subset]})\n",
    "\n",
    "# Convert class info list to pandas dataframe\n",
    "dataset_stats_df = pd.DataFrame(class_info)\n",
    "dataset_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with 1 row and 3 columns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
    "\n",
    "# Plot vertical bar plots for each mode in subplots\n",
    "for i, mode in enumerate(['train', 'valid', 'test']):\n",
    "  sns.barplot(\n",
    "    data = dataset_stats_df[dataset_stats_df['Subset'] == mode].drop(columns='Subset'),\n",
    "    orient='v',\n",
    "    ax = axes[i],\n",
    "    palette = 'Set2'\n",
    "  )\n",
    "\n",
    "  axes[i].set_title(f'{mode.capitalize()} Class Statistics')\n",
    "  axes[i].set_xlabel('Classes')\n",
    "  axes[i].set_ylabel('Count')\n",
    "  axes[i].tick_params(axis = 'x', rotation = 90)\n",
    "\n",
    "  # Add annotations on top of each bar\n",
    "  for p in axes[i].patches:\n",
    "    axes[i].annotate(f'{int(p.get_height())}',\n",
    "                      (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                      ha = 'center',\n",
    "                      va = 'center',\n",
    "                      fontsize = 8,\n",
    "                      color = 'black',\n",
    "                      xytext = (0,5),\n",
    "                      textcoords = 'offset points'\n",
    "                    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Images sizes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in [\"train\", \"valid\", \"test\"]:\n",
    "  print(f\"\\nImage size in {mode} set:\")\n",
    "\n",
    "  img_size = 0\n",
    "\n",
    "  for file in glob.glob(os.path.join(DATA_CFG.DATASET_PATH, mode, \"images\", \"*\")):\n",
    "\n",
    "    image = Image.open(file)\n",
    "\n",
    "    if image.size != img_size:\n",
    "      print(f\"{image.size}\")\n",
    "      img_size = image.size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
